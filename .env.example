# LLM Provider Configuration
LLM_PROVIDER=openai  # or 'ollama'

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.7

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=mistral
OLLAMA_MAX_TOKENS=1000
OLLAMA_TEMPERATURE=0.7

# Rate Limiting
RATE_LIMIT_WINDOW=60000
RATE_LIMIT_MAX_REQUESTS=10

# Chat Configuration
MAX_CHAT_HISTORY=50
CHAT_TIMEOUT=30000
CONTEXT_WINDOW=4096

# Environment
NODE_ENV=development
NEXT_PUBLIC_API_URL=http://localhost:3000/api
NEXT_PUBLIC_LLM_PROVIDER=openai

# Security
CORS_ORIGINS=http://localhost:3000